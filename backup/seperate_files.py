import pandas as pd
import os
import glob
import re

# 1) ìœ„ì—ì„œ ì •ì˜í•œ ì»¬ëŸ¼ ëª©ë¡ê³¼ ì²˜ë¦¬ í•¨ìˆ˜
'''COLUMNS_TO_DROP = [
    "ë‹¹ê¸°ì†ìµ-ê³µì •ê°€ì¹˜ì¸¡ì •ê¸ˆìœµìì‚°",
    "ê¸°íƒ€í¬ê´„ì†ìµ-ê³µì •ê°€ì¹˜ì¸¡ì •ê¸ˆìœµìì‚°",
    "ë³´í—˜ê³„ì•½ìì‚°",
    "ë³´í—˜ê³„ì•½ë¶€ì±„",
    "íŒŒìƒìƒí’ˆìì‚°",
    "íŒŒìƒìƒí’ˆë¶€ì±„",
    "ì´ììˆ˜ìµ",
    "ì´ìë¹„ìš©",
    "ì˜ì—…ì´ìµ(ì†ì‹¤)",
    "ì˜ì—…ë¹„ìš©",
    "ì˜ˆìˆ˜ë¶€ì±„",
    "ìˆœì´ìì†ìµ",
    "íŒŒìƒìƒí’ˆê´€ë ¨ì†ìµ",
    "ìˆœìˆ˜ìˆ˜ë£Œì†ìµ",
    "ì°¨ì…ë¶€ì±„",
    "ìƒê°í›„ì›ê°€ì¸¡ì •ê¸ˆìœµìì‚°"
]'''

COLUMNS_TO_DROP = []

def process_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.drop(columns=COLUMNS_TO_DROP, errors='ignore')
    return df


def merge_date_regression():
    merged_folder = "./data_kr/merged"
    output_folder = "./data_kr/date_regression"
    os.makedirs(output_folder, exist_ok=True)

    file_paths = glob.glob(os.path.join(merged_folder, "*.csv"))
    if not file_paths:
        print("merged í´ë” ë‚´ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_data = []
    for file in file_paths:
        try:
            df = pd.read_csv(file, encoding='utf-8-sig')
        except Exception as e:
            print(f"{file} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

        # ì—¬ê¸°ì„œ drop & ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬
        df = process_columns(df)

        if 'year' in df.columns and 'quarter' in df.columns:
            all_data.append(df)
        else:
            print(f"{file} íŒŒì¼ì— 'year' ë˜ëŠ” 'quarter' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    if not all_data:
        print("ë³‘í•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    combined_df = pd.concat(all_data, ignore_index=True)

    # ê·¸ë£¹í™” ì´ì „ì— drop & ì¬ì •ë ¬ì„ ë˜ í•˜ê³  ì‹¶ë‹¤ë©´ ì´ê³³ì—ì„œë„ ê°€ëŠ¥
    # combined_df = process_columns(combined_df)

    groups = combined_df.groupby(['year', 'quarter'])
    for (year, quarter), group in groups:
        # ê·¸ë£¹ë³„ë¡œë„ drop & ì¬ì •ë ¬ì„ ì ìš©í•  ìˆ˜ ìˆìŒ
        group = process_columns(group)

        output_file = os.path.join(output_folder, f"{year}_{quarter}.csv")
        group.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"ì—°ë„ {year}, ë¶„ê¸° {quarter} ë°ì´í„°ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def save_by_sector():
    merged_folder = "./data_kr/merged"
    output_base = "./data_kr/sector"
    os.makedirs(output_base, exist_ok=True)

    file_paths = glob.glob(os.path.join(merged_folder, "*.csv"))
    if not file_paths:
        print("merged í´ë” ë‚´ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    for file in file_paths:
        try:
            df = pd.read_csv(file, encoding='utf-8-sig')
        except Exception as e:
            print(f"{file} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

        if df.empty:
            print(f"{file} íŒŒì¼ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        if 'sector' not in df.columns or 'code' not in df.columns:
            print(f"{file} íŒŒì¼ì— 'sector' ë˜ëŠ” 'code' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            continue

        sector = df.iloc[0]['sector']
        code = df.iloc[0]['code']
        code_str = str(code)
        # 6ìë¦¬ ìˆ«ì í˜•ì‹(ì•ì— 0 í¬í•¨)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        if len(code_str) < 6:
            code_str = code_str.zfill(6)

        # ì„¹í„°ë³„ í´ë” ìƒì„± í›„ íŒŒì¼ ê·¸ëŒ€ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        sector_folder = os.path.join(output_base, str(sector))
        os.makedirs(sector_folder, exist_ok=True)
        output_file = os.path.join(sector_folder, f"{code_str}.csv")
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"ê¸°ì—… ì½”ë“œ {code_str}ì˜ ë°ì´í„°ê°€ ì„¹í„° '{sector}' í´ë”ì˜ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def filter_all_files_by_sector():
    # ì…ë ¥ ë””ë ‰í† ë¦¬ì™€ ì¶œë ¥ ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    input_dir = "./data_kr/date_regression"
    output_dir_base = "./data_kr/date_sector"

    # ì…ë ¥ ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  CSV íŒŒì¼ ê²€ìƒ‰
    csv_files = glob.glob(os.path.join(input_dir, "*.csv"))

    # ê° CSV íŒŒì¼ì— ëŒ€í•´ ì²˜ë¦¬
    for file_path in csv_files:
        file_name = os.path.basename(file_path)  # ì˜ˆ: "2023_Q1.csv"
        df = pd.read_csv(file_path)

        # 'sector'ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê° ê·¸ë£¹ì˜ ë°ì´í„°ë¥¼ ì €ì¥
        for sector, group in df.groupby('sector'):
            # í•´ë‹¹ sectorì— í•´ë‹¹í•˜ëŠ” ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            sector_output_dir = os.path.join(output_dir_base, str(sector))
            os.makedirs(sector_output_dir, exist_ok=True)

            # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            output_file = os.path.join(sector_output_dir, file_name)
            group.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"'{output_file}'ì— {sector} sector ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def save_sector_codes():
    # symbol.csv íŒŒì¼ ì½ê¸°
    df = pd.read_csv('./data_kr/symbol.csv')

    # sector ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”
    for sector in df['sector'].unique():
        # í•´ë‹¹ ì„¹í„°ì˜ ë°ì´í„°ë§Œ ì¶”ì¶œ
        sector_df = df[df['sector'] == sector]

        # 'code' ì»¬ëŸ¼ë§Œ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„
        sector_code_df = sector_df[['code']]

        # ì„¹í„°ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = f'./data_kr/date_sector/{sector}'
        os.makedirs(output_dir, exist_ok=True)

        # CSV íŒŒì¼ë¡œ ì €ì¥ (ì¸ë±ìŠ¤ ì œì™¸)
        output_file = f'{output_dir}/sector_code.csv'
        sector_code_df.to_csv(output_file, index=False, encoding='utf-8-sig')

        print(f"ì„¹í„° '{sector}'ì— ì†í•˜ëŠ” code {len(sector_code_df)}ê°œë¥¼ '{output_file}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


def print_csv_shapes(folder_path):
    """
    ì£¼ì–´ì§„ í´ë” ë‚´ì˜ ëª¨ë“  .csv íŒŒì¼ì˜ shapeì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Parameters:
    folder_path (str): .csv íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë”ì˜ ê²½ë¡œì…ë‹ˆë‹¤.
    """
    # í´ë” ë‚´ì˜ ëª¨ë“  íŒŒì¼ì„ í™•ì¸í•©ë‹ˆë‹¤.
    for file_name in os.listdir(folder_path):
        if file_name.endswith('.csv'):
            file_path = os.path.join(folder_path, file_name)
            try:
                df = pd.read_csv(file_path)
                print(f"{file_name}ì˜ shape: {df.shape}")
            except Exception as e:
                print(f"{file_name} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")



def compare_code_and_columns(file1, file2):
    """
    ë‘ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ 'code' ì»¬ëŸ¼ ê°’ì„ ë¹„êµí•˜ê³ , ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ì˜ ì°¨ì´ë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Parameters:
        file1 (str): ì²« ë²ˆì§¸ CSV íŒŒì¼ ê²½ë¡œ.
        file2 (str): ë‘ ë²ˆì§¸ CSV íŒŒì¼ ê²½ë¡œ.
    """
    # íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        df1 = pd.read_csv(file1)
        df2 = pd.read_csv(file2)
    except Exception as e:
        print(f"íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # 'code' ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if 'code' not in df1.columns:
        print(f"ì²« ë²ˆì§¸ íŒŒì¼({file1})ì— 'code' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    if 'code' not in df2.columns:
        print(f"ë‘ ë²ˆì§¸ íŒŒì¼({file2})ì— 'code' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ë‘ íŒŒì¼ ëª¨ë‘ 'code' ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš° ë¹„êµ ìˆ˜í–‰
    if 'code' in df1.columns and 'code' in df2.columns:
        code_set1 = set(df1['code'])
        code_set2 = set(df2['code'])

        diff1 = code_set1 - code_set2
        diff2 = code_set2 - code_set1

        print("ì²« ë²ˆì§¸ íŒŒì¼ì—ë§Œ ìˆëŠ” 'code' ê°’:")
        print(diff1)
        print("\në‘ ë²ˆì§¸ íŒŒì¼ì—ë§Œ ìˆëŠ” 'code' ê°’:")
        print(diff2)

    # ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ë¹„êµ
    cols1 = set(df1.columns)
    cols2 = set(df2.columns)

    cols_only_in_file1 = cols1 - cols2
    cols_only_in_file2 = cols2 - cols1

    print("\nì²« ë²ˆì§¸ íŒŒì¼ì—ë§Œ ìˆëŠ” ì»¬ëŸ¼:")
    print(cols_only_in_file1)
    print("\në‘ ë²ˆì§¸ íŒŒì¼ì—ë§Œ ìˆëŠ” ì»¬ëŸ¼:")
    print(cols_only_in_file2)


def remove_specific_codes(file_path):
    # ì œê±°í•  code ê°’ë“¤
    codes_to_remove = ['4990', '5830', '5940', '6800', '16360', '24110', '29780', '32830', '37620', '55550', '68870', '71050', '86790', '88350', '105560', '138930']
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv(file_path)

    # code ì»¬ëŸ¼ì´ codes_to_removeì— í¬í•¨ë˜ì§€ ì•Šì€ í–‰ë§Œ ë‚¨ê¹€
    df_filtered = df[~df['code'].isin(codes_to_remove)]

    # ë‹¤ì‹œ ê°™ì€ íŒŒì¼ë¡œ ì €ì¥
    df_filtered.to_csv(file_path, index=False)

    print(f"Filtered data saved to {file_path}")

def seperate_comma():
    input_path = './data_kr/symbol.csv'

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    output_path = './data_kr/kospi_200.txt'

    # CSV íŒŒì¼ ì½ê¸°
    symbol_df = pd.read_csv(input_path)

    # code ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ zfill(6) ì²˜ë¦¬
    symbol_df['code'] = symbol_df['code'].astype(str).str.zfill(6)

    # ,ë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    symbol_df.to_csv(output_path, index=False, sep=',')

    print(f"íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")

def saveUpjongtoSymbol():
    df_data = pd.read_csv('./data_kr/20201002_ì—…ì¢….csv', encoding='cp949')
    df_symbol = pd.read_csv('./data_kr/symbol.csv', encoding='utf-8-sig')

    # ì¢…ëª©ì½”ë“œ ë¬¸ìì—´ ë³€í™˜
    df_data['ì¢…ëª©ì½”ë“œ'] = df_data['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
    df_symbol['code'] = df_symbol['code'].astype(str).str.zfill(6)

    # ì¢…ëª©ì½”ë“œ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•˜ì—¬ sector ì¶”ê°€
    df_updated = pd.merge(df_symbol, df_data[['ì¢…ëª©ì½”ë“œ', 'ì—…ì¢…ëª…']],
                          how='left', left_on='code', right_on='ì¢…ëª©ì½”ë“œ')

    # ê¸°ì¡´ sector ì»¬ëŸ¼ ì‚­ì œí•˜ê³ , ìƒˆë¡œ ê°€ì ¸ì˜¨ 'ì—…ì¢…ëª…'ì„ sectorë¡œ ì‚¬ìš©
    df_updated.drop(columns=['sector', 'ì¢…ëª©ì½”ë“œ'], inplace=True)
    df_updated.rename(columns={'ì—…ì¢…ëª…': 'sector'}, inplace=True)

    # ê²°ê³¼ ì €ì¥
    df_updated.to_csv('./data_kr/symbol_upjong.csv', index=False)

def saveSectortoSymbol():
    # symbol.csv ë¶ˆëŸ¬ì˜¤ê¸°
    symbol_path = './data_kr/symbol.csv'
    sector_folder = './data_kr/ì„¹í„°ì •ë³´'
    output_path = './data_kr/symbol_sector.csv'
    df_symbol = pd.read_csv(symbol_path, encoding='utf-8-sig')
    df_symbol['code'] = df_symbol['code'].astype(str).str.zfill(6)
    df_symbol['sector'] = None  # sector ì—´ ì´ˆê¸°í™”

    # ì„¹í„° í´ë” ë‚´ ëª¨ë“  csv íŒŒì¼ ìˆœíšŒ
    for filename in os.listdir(sector_folder):
        if filename.endswith('.csv'):
            sector_name = os.path.splitext(filename)[0]  # íŒŒì¼ëª… (í™•ì¥ì ì œê±°) = ì„¹í„°ëª…
            sector_file_path = os.path.join(sector_folder, filename)

            # ì„¹í„° íŒŒì¼ ì½ê¸°
            df_sector = pd.read_csv(sector_file_path, encoding='utf-8-sig')
            if 'ì¢…ëª©ì½”ë“œ' not in df_sector.columns:
                continue  # ì¢…ëª©ì½”ë“œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ

            df_sector['ì¢…ëª©ì½”ë“œ'] = df_sector['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)

            # ì¢…ëª©ì½”ë“œ ë§¤ì¹­ë˜ëŠ” symbolì— ì„¹í„°ëª… ë„£ê¸°
            df_symbol.loc[df_symbol['code'].isin(df_sector['ì¢…ëª©ì½”ë“œ']), 'sector'] = sector_name

    # ê²°ê³¼ ì €ì¥
    df_symbol.to_csv(output_path, index=False, encoding='utf-8-sig')


def removeInvalidSymbolsAndFiles(folder_path, symbol_path, expected_rows=37, encoding='utf-8-sig'):
    # symbol.csv ë¶ˆëŸ¬ì˜¤ê¸°
    df_symbol = pd.read_csv(symbol_path, encoding=encoding)
    df_symbol['code'] = df_symbol['code'].astype(str).str.zfill(6)

    invalid_codes = []

    for filename in os.listdir(folder_path):
        if filename.endswith('.csv'):
            filepath = os.path.join(folder_path, filename)
            try:
                df = pd.read_csv(filepath, encoding=encoding)
                if df.shape[0] != expected_rows:
                    code = os.path.splitext(filename)[0].zfill(6)
                    invalid_codes.append(code)
                    os.remove(filepath)  # íŒŒì¼ ì‚­ì œ
                    print(f"[ì‚­ì œë¨] {filename} (í–‰ ê°œìˆ˜: {df.shape[0]})")
            except Exception as e:
                print(f"[ì˜¤ë¥˜] {filename} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                code = os.path.splitext(filename)[0].zfill(6)
                invalid_codes.append(code)
                try:
                    os.remove(filepath)
                    print(f"[ì‚­ì œë¨] ì˜¤ë¥˜ë‚œ íŒŒì¼ {filename}")
                except:
                    print(f"[ê²½ê³ ] {filename} ì‚­ì œ ì‹¤íŒ¨")

    # symbol.csvì—ì„œ ì½”ë“œ ì‚­ì œ
    before_count = df_symbol.shape[0]
    df_symbol = df_symbol[~df_symbol['code'].isin(invalid_codes)]
    after_count = df_symbol.shape[0]

    # ì €ì¥
    df_symbol.to_csv(symbol_path, index=False, encoding=encoding)

    print(f"\nì´ {before_count - after_count}ê°œì˜ ì¢…ëª© ì½”ë“œê°€ symbol.csvì—ì„œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    if invalid_codes:
        print("ì‚­ì œëœ ì¢…ëª©ì½”ë“œ ëª©ë¡:", invalid_codes)
    else:
        print("ëª¨ë“  CSV íŒŒì¼ì´ ìœ íš¨í•œ 37ê°œì˜ í–‰ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.")


def compareFolderAndSymbol(folder_path, symbol_path, encoding='utf-8-sig'):
    # í´ë” ë‚´ csv íŒŒì¼ ì´ë¦„ë“¤ â†’ ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸
    folder_codes = [
        os.path.splitext(f)[0].zfill(6)
        for f in os.listdir(folder_path)
        if f.endswith('.csv')
    ]

    # symbol.csvì˜ ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸
    df_symbol = pd.read_csv(symbol_path, encoding=encoding)
    symbol_codes = df_symbol['code'].astype(str).str.zfill(6).tolist()

    # ë¹„êµ
    only_in_folder = sorted(set(folder_codes) - set(symbol_codes))
    only_in_symbol = sorted(set(symbol_codes) - set(folder_codes))
    in_both = sorted(set(folder_codes) & set(symbol_codes))

    print(f"âœ… í´ë”ì—ë§Œ ìˆëŠ” ì½”ë“œ ({len(only_in_folder)}ê°œ): {only_in_folder}")
    print(f"âœ… symbol.csvì—ë§Œ ìˆëŠ” ì½”ë“œ ({len(only_in_symbol)}ê°œ): {only_in_symbol}")
    print(f"âœ… ë‘˜ ë‹¤ì— ìˆëŠ” ì½”ë“œ ({len(in_both)}ê°œ): {in_both[:10]}{' ...' if len(in_both) > 10 else ''}")  # ì¼ë¶€ë§Œ ì¶œë ¥

    return {
        "only_in_folder": only_in_folder,
        "only_in_symbol": only_in_symbol,
        "in_both": in_both
    }

def cleanSymbolWithFolder(folder_path, symbol_path, encoding='utf-8-sig'):
    # í´ë” ë‚´ íŒŒì¼ ì´ë¦„ë“¤ì—ì„œ ì¢…ëª©ì½”ë“œ ì¶”ì¶œ
    folder_codes = [
        os.path.splitext(f)[0].zfill(6)
        for f in os.listdir(folder_path)
        if f.endswith('.csv')
    ]

    # symbol.csv ë¡œë“œ
    df_symbol = pd.read_csv(symbol_path, encoding=encoding)
    df_symbol['code'] = df_symbol['code'].astype(str).str.zfill(6)

    # ë¹„êµ: symbol.csvì—ëŠ” ìˆì§€ë§Œ í´ë”ì— ì—†ëŠ” ì½”ë“œ
    symbol_codes = df_symbol['code'].tolist()
    only_in_symbol = sorted(set(symbol_codes) - set(folder_codes))

    # í•´ë‹¹ ì½”ë“œ ì œê±°
    before_count = len(df_symbol)
    df_symbol = df_symbol[~df_symbol['code'].isin(only_in_symbol)]
    after_count = len(df_symbol)

    # ì €ì¥
    df_symbol.to_csv(symbol_path, index=False, encoding=encoding)

    print(f"ì´ {before_count - after_count}ê°œì˜ ì¢…ëª©ì´ symbol.csvì—ì„œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    if only_in_symbol:
        print("ì‚­ì œëœ ì¢…ëª©ì½”ë“œ:", only_in_symbol)
    else:
        print("symbol.csvì™€ í´ë” ë‚´ íŒŒì¼ëª…ì´ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤.")

def add_disclosure_date(file_path, save_path=None):
    """
    CSV íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ deadlineê³¼ quarter ì—´ ê¸°ì¤€ìœ¼ë¡œ disclosure_dateë¥¼ ê³„ì‚°í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.

    :param file_path: str, ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
    :param save_path: str, ê²°ê³¼ë¥¼ ì €ì¥í•  ê²½ë¡œ (Noneì´ë©´ ê¸°ì¡´ ê²½ë¡œì— ë®ì–´ì“°ê¸°)
    """
    df = pd.read_csv(file_path)

    # datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    df['deadline'] = pd.to_datetime(df['deadline'], errors='coerce')

    # disclosure_date ì—´ ì¶”ê°€
    df['disclosure_date'] = df.apply(
        lambda row: row['deadline'] + pd.Timedelta(days=90) if row['quarter'] == 'Q4'
        else row['deadline'] + pd.Timedelta(days=45),
        axis=1
    )

    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    if save_path is None:
        save_path = file_path

    df.to_csv(save_path, index=False)
    print(f"ì €ì¥ ì™„ë£Œ: {save_path}")

def merge_LLM_date_regression(sector=" "):
    merged_folder = f"../preprocessed_data/llm/predict/{sector}"
    output_folder = f"../preprocessed_data/llm/date_regression/{sector}"
    os.makedirs(output_folder, exist_ok=True)

    file_paths = glob.glob(os.path.join(merged_folder, "*.csv"))
    if not file_paths:
        print("merged í´ë” ë‚´ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_data = []
    for file in file_paths:
        try:
            df = pd.read_csv(file, encoding='utf-8-sig')
        except Exception as e:
            print(f"{file} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

        # ì—¬ê¸°ì„œ drop & ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬
        df = process_columns(df)

        if 'year' in df.columns and 'quarter' in df.columns:
            all_data.append(df)
        else:
            print(f"{file} íŒŒì¼ì— 'year' ë˜ëŠ” 'quarter' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    if not all_data:
        print("ë³‘í•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    combined_df = pd.concat(all_data, ignore_index=True)

    # ê·¸ë£¹í™” ì´ì „ì— drop & ì¬ì •ë ¬ì„ ë˜ í•˜ê³  ì‹¶ë‹¤ë©´ ì´ê³³ì—ì„œë„ ê°€ëŠ¥
    # combined_df = process_columns(combined_df)

    groups = combined_df.groupby(['year', 'quarter'])
    for (year, quarter), group in groups:
        # ê·¸ë£¹ë³„ë¡œë„ drop & ì¬ì •ë ¬ì„ ì ìš©í•  ìˆ˜ ìˆìŒ
        group = process_columns(group)

        output_file = os.path.join(output_folder, f"{year}_{quarter}.csv")
        group.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"ì—°ë„ {year}, ë¶„ê¸° {quarter} ë°ì´í„°ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def merge_all_sectors_to_date_regression(base_merged_folder="../preprocessed_data/llm/predict",
                                          output_folder="../preprocessed_data/llm/date_regression/cluster_1"):
    os.makedirs(output_folder, exist_ok=True)

    # ëª¨ë“  ì„¹í„° í´ë”ì˜ ëª¨ë“  CSV ìˆ˜ì§‘
    all_csv_files = glob.glob(os.path.join(base_merged_folder, "*", "*.csv"))
    if not all_csv_files:
        print("ë³‘í•©í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_data = []
    for file in all_csv_files:
        try:
            df = pd.read_csv(file, encoding='utf-8-sig')
            df = process_columns(df)
            if 'year' in df.columns and 'quarter' in df.columns:
                all_data.append(df)
            else:
                print(f"{file} â†’ 'year' ë˜ëŠ” 'quarter' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"{file} â†’ íŒŒì¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if not all_data:
        print("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ëª¨ë“  ì„¹í„°ì˜ ë°ì´í„° í•˜ë‚˜ë¡œ ë³‘í•©
    combined_df = pd.concat(all_data, ignore_index=True)

    # ì—°ë„/ë¶„ê¸°ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì €ì¥
    groups = combined_df.groupby(['year', 'quarter'])
    for (year, quarter), group in groups:
        group = process_columns(group)
        group = group.sort_values(by="code")
        output_file = os.path.join(output_folder, f"{year}_{quarter}.csv")
        group.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ“ ì—°ë„ {year}, ë¶„ê¸° {quarter} ë°ì´í„°ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

import os
import chardet

def detect_csv_encodings(folder_path):
    for filename in os.listdir(folder_path):
        if filename.endswith(".csv"):
            file_path = os.path.join(folder_path, filename)
            try:
                with open(file_path, 'rb') as f:
                    raw_data = f.read(10000)  # ì²˜ìŒ 10KBë§Œ ìƒ˜í”Œë¡œ ì‚¬ìš©
                    result = chardet.detect(raw_data)
                    encoding = result['encoding']
                    confidence = result['confidence']
                    print(f"{filename}: encoding = {encoding}, confidence = {confidence:.2f}")
            except Exception as e:
                print(f"{filename}: ì—ëŸ¬ ë°œìƒ - {e}")


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import matplotlib.dates as mdates  # ë‚ ì§œ í˜•ì‹ ì§€ì •ì„ ìœ„í•´ ì¶”ê°€
import os


def set_korean_font():
    """ ìš´ì˜ì²´ì œì— ë§ëŠ” í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. """
    system_name = os.name

    if system_name == 'nt':  # Windows
        font_family = 'Malgun Gothic'
    elif system_name == 'darwin':  # Mac OS
        font_family = 'AppleGothic'
    else:  # Linux
        font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        if os.path.exists(font_path):
            font_family = 'NanumGothic'
        else:
            font_family = 'sans-serif'

    plt.rc('font', family=font_family)
    plt.rc('axes', unicode_minus=False)


def analyze_and_plot_performance(model_a_path: str, model_b_path: str, output_path: str, model_a_name, model_b_name):
    """
    ë‘ ëª¨ë¸ì˜ ì„±ê³¼ë¥¼ ë¶„ì„í•˜ê³ , ëˆ„ì ìˆ˜ìµë¥ ê³¼ ì›”ë³„ ì„±ê³¼ì°¨ì´ë¥¼ ì‹œê°í™”í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    try:
        df_a = pd.read_csv(model_a_path)
        df_b = pd.read_csv(model_b_path)

        for df in [df_a, df_b]:
            df['date'] = pd.to_datetime(df['date'])
            if 'return' not in df.columns:
                raise KeyError(f"íŒŒì¼ì— 'return' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ ì»¬ëŸ¼: {df.columns.tolist()}")

        df_a = df_a.rename(columns={'return': 'return_a'}).set_index('date')
        df_b = df_b.rename(columns={'return': 'return_b'}).set_index('date')

        merged_df = pd.merge(df_a[['return_a']], df_b[['return_b']], on='date', how='outer').fillna(0)

        merged_df['cumulative_a'] = (1 + merged_df['return_a']).cumprod() - 1
        merged_df['cumulative_b'] = (1 + merged_df['return_b']).cumprod() - 1
        merged_df['monthly_difference'] = (merged_df['return_a'] - merged_df['return_b']) * 100

        set_korean_font()
        fig, axes = plt.subplots(2, 1, figsize=(15, 14), sharex=True)
        fig.suptitle('ëª¨ë¸ A vs ëª¨ë¸ B ì„±ê³¼ ë¶„ì„', fontsize=20, y=0.95)

        # --- ì²« ë²ˆì§¸ ê·¸ë˜í”„: ëˆ„ì  ìˆ˜ìµë¥  ì¶”ì´ ---
        ax1 = axes[0]
        ax1.plot(merged_df.index, merged_df['cumulative_a'], label=f'{model_a_name} ëˆ„ì  ìˆ˜ìµë¥ ', color='crimson', linewidth=2)
        ax1.plot(merged_df.index, merged_df['cumulative_b'], label=f'{model_b_name} ëˆ„ì  ìˆ˜ìµë¥ ', color='royalblue', linewidth=2)
        ax1.set_title('ëª¨ë¸ë³„ ëˆ„ì  ìˆ˜ìµë¥  ì¶”ì´', fontsize=16)
        ax1.set_ylabel('ëˆ„ì  ìˆ˜ìµë¥ ', fontsize=12)
        ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))
        ax1.legend()
        ax1.grid(True, linestyle='--', linewidth=0.5)

        # --- ë‘ ë²ˆì§¸ ê·¸ë˜í”„: ì›”ë³„ ì„±ê³¼ ì°¨ì´ ---
        ax2 = axes[1]
        max_diff_date = merged_df['monthly_difference'].idxmax()
        min_diff_date = merged_df['monthly_difference'].idxmin()

        ax2.plot(merged_df.index, merged_df['monthly_difference'], label=f'ì›”ë³„ ì„±ê³¼ ì°¨ì´ ({model_a_name} - {model_b_name})', color='green')
        ax2.axhline(0, color='gray', linestyle='--', linewidth=1)
        ax2.scatter(max_diff_date, merged_df.loc[max_diff_date, 'monthly_difference'], color='red', s=80, zorder=5,
                    label=f'{model_a_name} ìµœëŒ€ ìš°ìœ„')
        ax2.scatter(min_diff_date, merged_df.loc[min_diff_date, 'monthly_difference'], color='blue', s=80, zorder=5,
                    label=f'{model_b_name} ìµœëŒ€ ìš°ìœ„')
        ax2.set_title('ì›”ë³„ ìˆ˜ìµë¥  ì°¨ì´', fontsize=16)
        ax2.set_xlabel('ë‚ ì§œ', fontsize=12)
        ax2.set_ylabel('ì´ˆê³¼ ìˆ˜ìµë¥  (%p)', fontsize=12)
        ax2.legend()
        ax2.grid(True, linestyle='--', linewidth=0.5)

        # --- [ìˆ˜ì •ëœ ë¶€ë¶„] xì¶• ë‚ ì§œ í˜•ì‹ ì§€ì • ---
        # ë‚ ì§œ í¬ë§·ì„ 'YYYY-MM' í˜•ì‹ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
        date_format = mdates.DateFormatter('%Y-%m')
        ax2.xaxis.set_major_formatter(date_format)

        # xì¶• ë¼ë²¨ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ 30ë„ íšŒì „ì‹œí‚µë‹ˆë‹¤.
        plt.setp(ax2.get_xticklabels(), rotation=30, ha="right")
        ax1.xaxis.set_major_formatter(date_format)

        # xì¶• ë¼ë²¨ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ 30ë„ íšŒì „ì‹œí‚µë‹ˆë‹¤.
        plt.setp(ax1.get_xticklabels(), rotation=30, ha="right")
        # --- [ìˆ˜ì • ë] ---

        # ë ˆì´ì•„ì›ƒì„ ì¡°ì ˆí•˜ì—¬ ë¼ë²¨ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
        fig.tight_layout(pad=2.5)

        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"'{output_dir}' ë””ë ‰í„°ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

        plt.savefig(output_path, dpi=300)
        print(f"\n[ì„±ê³µ] ë¶„ì„ ê·¸ë˜í”„ë¥¼ '{output_path}' ê²½ë¡œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        #plt.show()

    except FileNotFoundError as e:
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n{e}")
    except KeyError as e:
        print(f"ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm


def plot_kospi200_chart(csv_path: str):
    """
    ì£¼ì–´ì§„ CSV íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ KOSPI 200 ì§€ìˆ˜ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤.
    xì¶•ì€ ë§¤ë…„ 4ë¶„ê¸° ì‹œì‘ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ '{ì—°ë„}_Q4' í˜•ì‹ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.
    'KS200.csv' íŒŒì¼ì˜ 'ë‚ ì§œ', 'ì¢…ê°€' ì»¬ëŸ¼ëª…ì— ë§ì¶° ìˆ˜ì •ë˜ì—ˆìœ¼ë©°, ë²”ë¡€ê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.
    xì¶• ë²”ìœ„ëŠ” 2015ë…„ 4ë¶„ê¸°ë¶€í„° 2024ë…„ 4ë¶„ê¸°ê¹Œì§€ë¡œ ì œí•œë©ë‹ˆë‹¤.
    xì¶•/yì¶• ë¼ë²¨ê³¼ ëˆˆê¸ˆ ê°’ ëª¨ë‘ í¬ê³  êµµê²Œ í‘œì‹œë©ë‹ˆë‹¤.

    Args:
        csv_path (str): KOSPI 200 ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ì˜ ê²½ë¡œ.
    """
    try:
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        try:
            plt.rc('font', family='Malgun Gothic')  # Windows
        except:
            try:
                plt.rc('font', family='AppleGothic')  # macOS
            except:
                font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
                if fm.findfont(fm.FontProperties(fname=font_path)):
                    plt.rc('font', family=fm.FontProperties(fname=font_path).get_name())
        plt.rcParams['axes.unicode_minus'] = False

        # 1. CSV íŒŒì¼ ì½ê¸° ë° ë°ì´í„° í•„í„°ë§
        df = pd.read_csv(csv_path, parse_dates=['ë‚ ì§œ'], index_col='ë‚ ì§œ')
        df.sort_index(inplace=True)
        start_date = '2015-10-01'
        end_date = '2024-10-01'
        df_filtered = df.loc[start_date:end_date].copy()

        if df_filtered.empty:
            print(f"ì˜¤ë¥˜: {start_date}ë¶€í„° {end_date}ê¹Œì§€ì˜ ë°ì´í„°ê°€ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
            return

        price_column = 'ì¢…ê°€'
        if price_column not in df_filtered.columns:
            raise ValueError(f"ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ê°€ê²© ë°ì´í„° ì»¬ëŸ¼('{price_column}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. ê·¸ë˜í”„ ìƒì„±
        fig, ax = plt.subplots(figsize=(17, 8))  # ì„¸ë¡œ ê¸¸ì´ë¥¼ ì¡°ê¸ˆ ëŠ˜ë ¤ ê³µê°„ í™•ë³´
        ax.plot(df_filtered.index, df_filtered[price_column], color='royalblue',linewidth=2.5)

        # 3. xì¶• ëˆˆê¸ˆ ë° ë ˆì´ë¸” ì„¤ì •
        years = range(2015, 2025)
        xticks = [pd.Timestamp(f'{year}-10-01') for year in years]
        xtick_labels = [f'{year-2000}/10' for year in years]
        ax.set_xticks(xticks)
        ax.set_xticklabels(xtick_labels, ha='center',fontsize=8)

        # 4. xì¶• ë²”ìœ„ ëª…ì‹œì  ì„¤ì •
        ax.set_xlim(pd.Timestamp(start_date), pd.Timestamp(end_date))
        ax.set_ylim(160,450)

        # 5. ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ë° ì •ë³´ ì¶”ê°€
        #ax.set_title('KOSPI 200 ì§€ìˆ˜ (2015_Q4 - 2024_Q4)', fontsize=18, fontweight='bold', pad=20)
        ax.set_ylabel('KOSPI200 Index', fontsize=25, fontweight='bold')
        ax.set_xlabel('Date', fontsize=25, fontweight='bold')

        # 6. xì¶•ê³¼ yì¶• ëˆˆê¸ˆ ê°’ ìŠ¤íƒ€ì¼ ë³€ê²½ (ìˆ˜ì •ëœ ë¶€ë¶„)
        # ê¸€ì”¨ í¬ê¸°ë¥¼ 12ë¡œ, êµµê²Œ(bold) ì„¤ì •
        plt.setp(ax.get_xticklabels(), fontsize=20, fontweight='bold')
        plt.setp(ax.get_yticklabels(), fontsize=20, fontweight='bold')


        for spine in ax.spines.values():
            spine.set_linewidth(1.5)

        # 'color'ë¥¼ 'facecolor'ë¡œ ë³€ê²½í•˜ì—¬ ë©´ê³¼ í…Œë‘ë¦¬ ìƒ‰ì„ ë¶„ë¦¬
        ax.axvspan('2020-10-01', '2021-10-01', facecolor='skyblue', alpha=0.3, edgecolor='black', linewidth=3, zorder=-4)
        ax.axvspan('2021-10-01', '2022-10-01', facecolor='lightgreen', alpha=0.3, edgecolor='black', linewidth=3,
                   zorder=-3)
        ax.axvspan('2022-10-01', '2023-10-01', facecolor='yellow', alpha=0.3, edgecolor='black', linewidth=3, zorder=-2)
        ax.axvspan('2023-10-01', '2024-10-01', facecolor='lightpink', alpha=0.3, edgecolor='black', linewidth=3,
                   zorder=-1)
        # yì¶• 400~450 & xì¶• 2016-10-01 ~ 2020-10-01 ì˜ì—­ì„ íˆ¬ëª… íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œ
        ax.fill_between([pd.to_datetime('2015-10-01'), pd.to_datetime('2020-10-01')], 400, 450, color='lightgray', alpha=1,
                        zorder=-3.5)
        ax.fill_between([pd.to_datetime('2016-10-01'), pd.to_datetime('2021-10-01')], 350, 400, color='lightgray', alpha=1,
                        zorder=-2.5)
        #ax.fill_between([pd.to_datetime('2018-10-01'), pd.to_datetime('2022-10-01')], 300, 350, color='lightgray', alpha=1,zorder=-1.5)
        #ax.fill_between([pd.to_datetime('2019-10-01'), pd.to_datetime('2023-10-01')], 250, 300, color='lightgray', alpha=1,zorder=-0.5)
        ax.grid(True, linestyle='-', alpha=0.6)

        # ë ˆì´ì•„ì›ƒì„ ì¡°ì •í•˜ì—¬ ë¼ë²¨ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
        plt.tight_layout()
        plt.show();

    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{csv_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except KeyError as e:
        print(f"ì˜¤ë¥˜: CSV íŒŒì¼ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼({e})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


import pandas as pd
import glob
import os


def analyze_merged_csv(folder_path):
    """
    ì§€ì •ëœ í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ì„ ì„¸ë¡œë¡œ ë³‘í•©í•˜ê³ , ì—´ ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    ì´í›„ ê²°ì¸¡ì¹˜ê°€ 50%ê°€ ë„˜ëŠ” ì—´ê³¼ í•´ë‹¹ ì—´ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        folder_path (str): CSV íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•œ í´ë”ì˜ ê²½ë¡œì…ë‹ˆë‹¤.
                           ì˜ˆ: './data_kr/merged/'
    """
    # 1. í´ë” ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  CSV íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    all_csv_files = glob.glob(os.path.join(folder_path, "*.csv"))

    if not all_csv_files:
        print(f"'{folder_path}' í´ë”ì—ì„œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ¤·")
        return

    # 2. ì°¾ì€ ëª¨ë“  CSV íŒŒì¼ì„ ìˆœì„œëŒ€ë¡œ ì½ì–´ ë°ì´í„°í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    df_list = [pd.read_csv(file) for file in all_csv_files]
    print(f"ì´ {len(df_list)}ê°œì˜ CSV íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    # 3. ë°ì´í„°í”„ë ˆì„ë“¤ì„ ì„¸ë¡œ ë°©í–¥(axis=0)ìœ¼ë¡œ ëª¨ë‘ í•©ì¹©ë‹ˆë‹¤.
    # ignore_index=TrueëŠ” ê¸°ì¡´ íŒŒì¼ë“¤ì˜ ì¸ë±ìŠ¤ë¥¼ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ì¸ë±ìŠ¤ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
    merged_df = pd.concat(df_list, axis=0, ignore_index=True)
    print("âœ… ëª¨ë“  CSV íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë³‘í•©í–ˆìŠµë‹ˆë‹¤!")

    print("-" * 50)  # êµ¬ë¶„ì„ ìœ„í•œ ë¼ì¸

    # 4. ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„ì˜ ì „ì²´ ì—´ ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    print("ğŸ“‹ ë³‘í•© í›„ ì „ì²´ ì—´ ëª©ë¡ì…ë‹ˆë‹¤:")
    print(merged_df.columns.tolist())

    print("-" * 50)  # êµ¬ë¶„ì„ ìœ„í•œ ë¼ì¸

    # 5. ê²°ì¸¡ì¹˜ê°€ 50%ê°€ ë„˜ëŠ” ì—´ì„ ì°¾ì•„ ê²°ì¸¡ì¹˜ ì •ë³´ì™€ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤.
    print("ğŸ” ê²°ì¸¡ì¹˜ê°€ 50% ì´ìƒì¸ ì—´ ëª©ë¡ì…ë‹ˆë‹¤:")

    # ì „ì²´ í–‰ì˜ ê°œìˆ˜ë¥¼ êµ¬í•©ë‹ˆë‹¤.
    total_rows = len(merged_df)
    # ê° ì—´ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    missing_values = merged_df.isnull().sum()

    # ê²°ì¸¡ì¹˜ê°€ 50%ë¥¼ ë„˜ëŠ” ì—´ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ í”Œë˜ê·¸
    found_missing_columns = False

    for column_name, missing_count in missing_values.items():
        if missing_count == 0:
            continue

        # ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        missing_percentage = (missing_count / total_rows) * 100

        # ë¹„ìœ¨ì´ 50%ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° í•´ë‹¹ ì—´ì˜ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        if missing_percentage > 50:
            print(f"  - ì—´ ì´ë¦„: '{column_name}'")
            print(f"    - ê²°ì¸¡ì¹˜ ê°œìˆ˜: {missing_count}ê°œ")
            print(f"    - ê²°ì¸¡ì¹˜ ë¹„ìœ¨: {missing_percentage:.2f}%")
            found_missing_columns = True

    if not found_missing_columns:
        print("ê²°ì¸¡ì¹˜ê°€ 50% ì´ìƒì¸ ì—´ì´ ì—†ìŠµë‹ˆë‹¤. âœ¨")


# --- í•¨ìˆ˜ ì‹¤í–‰ ---
# ì•„ë˜ ë³€ìˆ˜ì— ë¶„ì„í•˜ê³  ì‹¶ì€ CSV íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.
TARGET_FOLDER_PATH = './data_kr/merged/'

# í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.
analyze_merged_csv(TARGET_FOLDER_PATH)