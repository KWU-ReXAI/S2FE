지난 1편에서는 AI 발전에 따른
부작용에 대해
살펴봤는데요이어서 AI 리스크 예방을
위해 전 세계가 어떤 노력을 펼치고
있는지 자세히
알아보겠습니다 먼저 지난해 영국에서
개최된 인공지능 안전성 정상회의는
한미 중 등 28개국이 합의한 AI
안전 공동선언문을 발표했는데요
합의문에서 안전하고 신뢰할 수 있는
AI 설계와 백포 개발자의 책임 과
국제 협력의 중요성 등이 강조됐습니다
OECD 있는 지속 가능하고 신뢰할
수 있는 AI 구현을 위한 OECD
AI 권고안을
채택했는데요이는 최초로 마련된 AI
규범으로 AI 다양성과 포용성 공정성
투명성 등을 강조하고 있습니다
유네스코는 AI 윤리에 대한 권고를
마련했습니다 여기에는 AI 지향해야
할 사대 가치와 개 원칙 11개 정책
권고를 포함하고 있는데
사대 가치에는 인권 자유 인간 존중
및 환경 및 생태계 번영 등의 내용을
담아냈습니다 이유는 AI 기술 규제
법안인 후 AI 법안을 통과시켰습니다
동 법안을 기반으로 AI 위험성을
4단계로 분류하고 고위험 AI
시스템에 대한 인간의 감독 고위험
AI 시스템 사업자가 준수해야 할
의무 등을 규정했습니다 미국은
알고리즘의 투명성과 책임성을 강조한
알고리즘 책임 법안을 발 했는데요
AI 시스템이 차별이나 개인 정보
치매 등의 평가를 준수하지 않을 시
관할 당국의 법집행이 가능하도록
했습니다이 외에도 미국은 안정적이고
신뢰할 수 있는 AI 행정 명령을
발표하며 AI 기술 오용을 막기 위한
보다 강력한 의무를 부과했습니다
이러한 글로벌 동향에 맞춰 국내에서는
AI 저작권 관련 가이드라인 규정에
이어 인공지능 서비스 이용자 보호에
관한 법률 재정을 추진하고 있는 요
AI 생성물 표시제 도입과 AI 신고
전담 창구 신설 계획을
공표했습니다 AI 성장은 기업과
국가에게 큰 기회가 될 수도 있지만
부정적인 영향을 주는 AI 제품이나
서비스가 개발된다면 그만큼 큰 대가를
치뤄야 합니다 따라서 국제 사회
법규와 규범을 바탕으로 안전하고 지속
가능한 AI 개발할 수 있도록 만전을
기해야할 것입니다 아에 대한 여러
가지 인사이트를 더 얻고 싶다 언제든
삼성 sds 홈페이지를 방문해 주세요
감사합니다