{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4e4614-6333-4564-b23b-d59ca6a4a8d2",
   "metadata": {},
   "source": [
    "### 오디오 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9320139f-722c-4682-93f8-5e6da877e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import extract_video_audio\n",
    "\n",
    "df = pd.read_csv(\"data_kr/video/자료 수집 최종본.csv\")\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if pd.isna(row.url) or row.url == '' or row.category != \"video\":\n",
    "        continue\n",
    "\n",
    "    code = str(row.code).zfill(6)\n",
    "    audio_dir = f'data_kr/video/audio/{row.sector}/{code}/'\n",
    "    text_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "    if audio_dir + f'{row.year}-{row.quarter}' != 'data_kr/video/audio/산업재/003490/2016-Q2':\n",
    "        continue\n",
    "    \n",
    "    if extract_video_audio(\"link\", row.url, audio_dir + f'{row.year}-{row.quarter}'):\n",
    "        with open('data_kr/video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} audio download completed: {audio_dir + f'{row.year}-{row.quarter}'}\\n\")\n",
    "    else:\n",
    "        with open('data_kr/video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} audio download error: {audio_dir + f'{row.year}-{row.quarter}'}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1dc206-96f3-4bf2-9b25-09b38ab4529c",
   "metadata": {},
   "source": [
    "### 텍스트로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448eb2f-9bec-4513-8714-ad550cccffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import audio2text\n",
    "\n",
    "df = pd.read_csv(\"data_kr/video/자료 수집 최종본.csv\")\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if pd.isna(row.url) or row.url == '' or row.category != \"video\":\n",
    "        continue\n",
    "\n",
    "    code = str(row.code).zfill(6)\n",
    "    audio_dir = f'data_kr/video/audio/{row.sector}/{code}/'\n",
    "    text_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "    os.makedirs(text_dir, exist_ok=True)\n",
    "    \n",
    "    if audio_dir + f'{row.year}-{row.quarter}' != 'data_kr/video/audio/산업재/003490/2016-Q2':\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        text = audio2text(audio_dir + f'{row.year}-{row.quarter}')\n",
    "        with open(text_dir + f'{row.year}-{row.quarter}.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "        with open('data_kr/video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} whisper completed: {text_dir + f'{row.year}-{row.quarter}'}\\n\")\n",
    "    except Exception as e:\n",
    "        with open('data_kr/video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} whisper error: {text_dir + f'{row.year}-{row.quarter}'}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c7ccf-1dea-4696-aa6d-d36f5e4dee1b",
   "metadata": {},
   "source": [
    "### 텍스트 token 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3802c4-52df-4dde-a9f5-d7b9eccfcb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_kr/video/자료 수집 최종본.csv\")\n",
    "\n",
    "import tiktoken\n",
    "# 예: GPT-4용 인코더 불러오기\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "total_tokens = 0\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"checking tokens\"):\n",
    "\tif pd.isna(row.url) or row.url == '':\n",
    "\t\tcontinue\n",
    "\n",
    "\tcode = str(row.code).zfill(6)\n",
    "\ttext_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "\tos.makedirs(text_dir, exist_ok=True)\n",
    "    \n",
    "\ttry:\n",
    "\t\tfilename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "\t\twith open(text_dir + filename, \"r\", encoding=\"utf-8\") as file:\n",
    "\t\t\ttext = file.read()\n",
    "\t\t\tsystem_prompt = \"\"\"\n",
    "\t\t너는 경제 전문 뉴스 분석 AI야. 사용자가 지정한 종목(회사명)과 직접적으로 관련된 정보만 선택해 핵심적으로 요약해.\n",
    "\t\t사실 기반으로 요약하고, 감성이나 추론이 필요한 경우에는 중립적으로 표현해.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t\tuser_prompt = f\"\"\"\n",
    "\t\t다음은 경제 뉴스 기사입니다.\n",
    "\n",
    "\t\t이 기사에서 **한국 상장 기업 \"{code}\"**과 관련된 내용만 골라 요약해 주세요.\n",
    "\n",
    "\t\t요약 기준:\n",
    "\t\t- \"{code}\"이 언급된 부분 중심\n",
    "\t\t- 관련 사업, 실적, 주가, 시장 반응, 경쟁사와의 연관성\n",
    "\t\t- 정부 정책, 산업 트렌드 등 외부 요인 중 관련 있는 부분\n",
    "\t\t- 부정적/긍정적 논조도 간단히 언급 (있는 경우)\n",
    "\n",
    "\t\t형식은 간결한 문장 또는 Bullet Point 형식으로 작성해 주세요.\n",
    "\n",
    "\t\t기사 전문:\n",
    "\t\t{text}\n",
    "\t\t\"\"\"\n",
    "\t\t\ttotal_prompt = system_prompt + user_prompt\n",
    "\t\t\ttokens = encoding.encode(total_prompt)\n",
    "\t\t\ttotal_tokens += len(tokens)\n",
    "\t\twith open('data_kr/video/num_token.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "\t\t\ttimestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "\t\t\tlog_file.write(f\"{text_dir}{filename} len: {len(text)}, token: {len(tokens)}\\n\")\n",
    "\texcept Exception as e:\n",
    "\t\twith open('data_kr/video/num_token.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "\t\t\ttimestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "\t\t\tlog_file.write(f\"{text_dir}{filename} error: \" + e + \"\\n\")\n",
    "\n",
    "with open('data_kr/video/num_token.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "\tlog_file.write(f\"total tokens: {total_tokens}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d9d4c-6adf-4f55-b874-ecfb5d6b58a7",
   "metadata": {},
   "source": [
    "### LLM으로 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e4c23-ba5a-4768-8ded-6e69e51f8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import summarize_text\n",
    "\n",
    "df = pd.read_csv(\"data_kr/video/자료 수집 최종본.csv\")\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"LLM summarizing\"):\n",
    "    if pd.isna(row.url) or row.url == '':\n",
    "        continue\n",
    "\n",
    "    code = str(row.code).zfill(6)\n",
    "    name = row.name\n",
    "    text_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "    summary_dir = f'preprocessed_data/llm/summary/{row.sector}/{code}/'\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "        \n",
    "    try:\n",
    "        filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "        stock = f'{name}({code})'\n",
    "        with open(text_dir + filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        summary = summarize_text(text, stock)\n",
    "        with open(summary_dir + filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summary)\n",
    "        with open('preprocessed_data/llm/summary/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} summary completed: {summary_dir + filename}\\n\")\n",
    "    except Exception as e:\n",
    "        with open('preprocessed_data/llm/summary/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} summary error: {summary_dir + filename}\\t error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f08c86-f82f-476a-b5a9-a9c47e242a4d",
   "metadata": {},
   "source": [
    "### LLM으로 기사 자막요약을 통해 등락 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea05f01-d708-4647-bce7-2cdbad1dcf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import predict_market_from_summary\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_kr/video/뉴스 기사 수집본.csv', encoding='utf-8')\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    \n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\t\n",
    "        name = row.name\n",
    "        article_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "        predict_dir = f'preprocessed_data/llm/predict_text/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{article_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                article = file.read()\n",
    "            data = predict_market_from_summary(article, f'{name}({code})')\n",
    "            \n",
    "            with open(f'{predict_dir}{filename}', \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(data)\n",
    "            \n",
    "            with open('preprocessed_data/llm/predict_text/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict completed: {predict_dir}{filename}\\n\")\n",
    "        except Exception as e:\n",
    "            with open('preprocessed_data/llm/predict_text/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict error: {predict_dir}{filename}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83cdb794-3b2a-4a43-94d0-568caa5807b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120LLM predicting: 100%|██████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 412.82it/s]\n",
      "150LLM predicting: 100%|██████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 617.09it/s]\n",
      "660LLM predicting: 100%|██████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 552.95it/s]\n",
      "1120LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 397.84it/s]\n",
      "3490LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 424.63it/s]\n",
      "3550LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 569.39it/s]\n",
      "3570LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 927.62it/s]\n",
      "4710LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 831.48it/s]\n",
      "5930LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 613.49it/s]\n",
      "6260LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 542.60it/s]\n",
      "6400LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 414.28it/s]\n",
      "8060LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 398.77it/s]\n",
      "9150LLM predicting: 100%|█████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 367.26it/s]\n",
      "10120LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 425.64it/s]\n",
      "11070LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 372.10it/s]\n",
      "11200LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 421.77it/s]\n",
      "18260LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 473.90it/s]\n",
      "20150LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 337.28it/s]\n",
      "25540LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 601.75it/s]\n",
      "29530LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 667.83it/s]\n",
      "34220LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 407.46it/s]\n",
      "34730LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 448.72it/s]\n",
      "42700LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 439.04it/s]\n",
      "47050LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 348.29it/s]\n",
      "47810LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 451.53it/s]\n",
      "51600LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 414.43it/s]\n",
      "66570LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 426.75it/s]\n",
      "86280LLM predicting: 100%|████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 445.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from predict_stock_outlook import predict_market_from_summary\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_kr/video/뉴스 기사 수집본.csv', encoding='utf-8')\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    \n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\t\n",
    "        name = row.name\n",
    "        predict_dir = f'preprocessed_data/llm/predict_text/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{predict_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                prediction = file.read()\n",
    "            prediction = prediction.removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
    "            \n",
    "            with open(f'{predict_dir}{filename}', \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(prediction)\n",
    "            \n",
    "            with open('preprocessed_data/llm/predict_text/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict completed: {predict_dir}{filename}\\n\")\n",
    "        except Exception as e:\n",
    "            with open('preprocessed_data/llm/predict_text/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict error: {predict_dir}{filename}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf24048-7d41-471e-855b-d400cca54424",
   "metadata": {},
   "source": [
    "### LLM으로 영상 자막요약을 통해 등락 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b6896-89df-4897-9c2d-cd991044ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import predict_market_from_summary\n",
    "\n",
    "df = pd.read_csv('data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    \n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\t\n",
    "        name = row.name\n",
    "        summary_dir = f'preprocessed_data/llm/summary_video/{row.sector}/{code}/'\n",
    "        predict_dir = f'preprocessed_data/llm/predict_video/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{summary_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                summary = file.read()\n",
    "            data = predict_market_from_summary(summary, f'{name}({code})')\n",
    "            \n",
    "            with open(f'{predict_dir}{filename}', \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(data)\n",
    " \n",
    "            predict = data.split('\\n')[0].split(':')[1].strip()\n",
    "            reason = data.split('\\n')[1].split(':')[1].strip()\n",
    "            predict_list.append(predict)\n",
    "            reason_list.append(reason)\n",
    "            \n",
    "            with open('preprocessed_data/llm/predict_video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict completed: {predict_dir}{filename}\\n\")\n",
    "        except Exception as e:\n",
    "            with open('preprocessed_data/llm/predict_video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict error: {predict_dir}{filename}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684e553-90a5-401e-bbd4-ff1bde25fb2b",
   "metadata": {},
   "source": [
    "### LLM으로 영상자막요약 + 기사자막요약을 통해 등락 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e394fd-4a0c-4b3e-9976-76fcd09e4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import predict_market_from_summary\n",
    "\n",
    "df_v = pd.read_csv('data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')\n",
    "df_v.rename(columns={'url':'v_url', 'upload_dt':'v_upload_dt'}, inplace=True)\n",
    "df_v = df_v[[\"year\",\"quarter\",\"month\",\"week\",\"code\",\"name\",\"sector\",\"after\",\"before\",\"v_url\",\"v_upload_dt\"]]\n",
    "\n",
    "df_a = pd.read_csv('data_kr/video/뉴스 기사 수집본.csv', encoding='utf-8')\n",
    "df_a.rename(columns={'url':'a_url', 'upload_dt':'a_upload_dt'}, inplace=True)\n",
    "df_a = df_a[[\"a_url\",\"a_upload_dt\"]]\n",
    "\n",
    "df = pd.concat([df_v, df_a], axis=1)\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    \n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.v_url) or pd.isna(row.a_url) :\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\n",
    "        name = row.name\n",
    "        v_summary_dir = f'preprocessed_data/llm/summary_video/{row.sector}/{code}/'\n",
    "        t_summary_dir = f'preprocessed_data/llm/summary_text/{row.sector}/{code}/'\n",
    "        predict_dir = f'preprocessed_data/llm/predict_mix/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{v_summary_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                v_summary = file.read()\n",
    "            with open(f'{t_summary_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                t_summary = file.read()\n",
    " \n",
    "            data = predict_market_from_summary(v_summary + t_summary, f'{name}({code})')\n",
    "            \n",
    "            with open(f'{predict_dir}{filename}', \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(data)\n",
    " \n",
    "            predict = data.split('\\n')[0].split(':')[1].strip()\n",
    "            reason = data.split('\\n')[1].split(':')[1].strip()\n",
    "            predict_list.append(predict)\n",
    "            reason_list.append(reason)\n",
    "            \n",
    "            with open('preprocessed_data/llm/predict_mix/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict completed: {predict_dir}{filename}\\n\")\n",
    "        except Exception as e:\n",
    "            with open('preprocessed_data/llm/predict_mix/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict error: {predict_dir}{filename}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a9a1b-c4ca-473d-917e-86af4d5e011c",
   "metadata": {},
   "source": [
    "### 기사 예측 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5e488-346e-4161-8b26-ee4ab9d49bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data_kr/video/뉴스 기사 수집본.csv', encoding='utf-8')\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            score_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\t\n",
    "        name = row.name\n",
    "        predict_dir = f'preprocessed_data/llm/predict_text/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{predict_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "                \n",
    "            predict = data.split('\\n')[0].split(':')[1].strip()\n",
    "            reason = data.split('\\n')[1].split(':')[1].strip()\n",
    "            score = data.split('\\n')[2].split(':')[1].strip()\n",
    "            predict_list.append(predict)\n",
    "            reason_list.append(reason)\n",
    "            score_list.append(int(score))\n",
    "            \n",
    "        except Exception as e:\n",
    "            predict_list.append(\"중립\")\n",
    "            reason_list.append(\"관련 없음\")\n",
    "            score_list.append(0)\n",
    "            \n",
    "    df_predict = df_.copy()\n",
    "    df_predict[\"prediction\"] = predict_list\n",
    "    df_predict[\"reason\"] = reason_list\n",
    "    df_predict[\"score\"] = score_list\n",
    "    df_predict = df_predict[[\"year\", \"quarter\", \"month\", \"week\", \"code\", \"name\", \"sector\", \"upload_dt\", \"prediction\", \"reason\", \"score\"]]\n",
    "    df_predict.to_csv(f\"{predict_dir}{code}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95054901-f78d-4671-87aa-9e6931a13628",
   "metadata": {},
   "source": [
    "### 영상 예측 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1cdce-09e6-4828-8434-465f7dff3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            score_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\t\n",
    "        name = row.name\n",
    "        predict_dir = f'preprocessed_data/llm/predict_video/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{predict_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "                \n",
    "            predict = data.split('\\n')[0].split(':')[1].strip()\n",
    "            reason = data.split('\\n')[1].split(':')[1].strip()\n",
    "            score = data.split('\\n')[2].split(':')[1].strip()\n",
    "            predict_list.append(predict)\n",
    "            reason_list.append(reason)\n",
    "            score_list.append(int(score))\n",
    "            \n",
    "        except Exception as e:\n",
    "            predict_list.append(\"불가능\")\n",
    "            reason_list.append(\"관련 없음\")\n",
    "            score_list.append(0)\n",
    "            \n",
    "    df_predict = df_.copy()\n",
    "    df_predict[\"prediction\"] = predict_list\n",
    "    df_predict[\"reason\"] = reason_list\n",
    "    df_predict[\"score\"] = score_list\n",
    "    df_predict = df_predict[[\"year\", \"quarter\", \"month\", \"week\", \"code\", \"name\", \"sector\", \"upload_dt\", \"prediction\", \"reason\", \"score\"]]\n",
    "    df_predict.to_csv(f\"{predict_dir}{code}.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3ce_kernel",
   "language": "python",
   "name": "s3ce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
