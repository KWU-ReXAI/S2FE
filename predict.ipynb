{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4e4614-6333-4564-b23b-d59ca6a4a8d2",
   "metadata": {},
   "source": [
    "### 오디오 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9320139f-722c-4682-93f8-5e6da877e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import extract_video_audio\n",
    "\n",
    "df = pd.read_csv(\"data_kr/video/자료 수집 최종본.csv\")\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if pd.isna(row.url) or row.url == '' or row.category != \"video\":\n",
    "        continue\n",
    "\n",
    "    code = str(row.code).zfill(6)\n",
    "    audio_dir = f'data_kr/video/audio/{row.sector}/{code}/'\n",
    "    text_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "    if audio_dir + f'{row.year}-{row.quarter}' != 'data_kr/video/audio/산업재/003490/2016-Q2':\n",
    "        continue\n",
    "    \n",
    "    if extract_video_audio(\"link\", row.url, audio_dir + f'{row.year}-{row.quarter}'):\n",
    "        with open('data_kr/video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} audio download completed: {audio_dir + f'{row.year}-{row.quarter}'}\\n\")\n",
    "    else:\n",
    "        with open('data_kr/video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} audio download error: {audio_dir + f'{row.year}-{row.quarter}'}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1dc206-96f3-4bf2-9b25-09b38ab4529c",
   "metadata": {},
   "source": [
    "### 텍스트로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448eb2f-9bec-4513-8714-ad550cccffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import audio2text\n",
    "\n",
    "df = pd.read_csv(\"data_kr/video/자료 수집 최종본.csv\")\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if pd.isna(row.url) or row.url == '' or row.category != \"video\":\n",
    "        continue\n",
    "\n",
    "    code = str(row.code).zfill(6)\n",
    "    audio_dir = f'data_kr/video/audio/{row.sector}/{code}/'\n",
    "    text_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "    os.makedirs(text_dir, exist_ok=True)\n",
    "    \n",
    "    if audio_dir + f'{row.year}-{row.quarter}' != 'data_kr/video/audio/산업재/003490/2016-Q2':\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        text = audio2text(audio_dir + f'{row.year}-{row.quarter}')\n",
    "        with open(text_dir + f'{row.year}-{row.quarter}.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "        with open('data_kr/video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} whisper completed: {text_dir + f'{row.year}-{row.quarter}'}\\n\")\n",
    "    except Exception as e:\n",
    "        with open('data_kr/video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} whisper error: {text_dir + f'{row.year}-{row.quarter}'}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c7ccf-1dea-4696-aa6d-d36f5e4dee1b",
   "metadata": {},
   "source": [
    "### 텍스트 token 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3802c4-52df-4dde-a9f5-d7b9eccfcb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_kr/video/자료 수집 최종본.csv\")\n",
    "\n",
    "import tiktoken\n",
    "# 예: GPT-4용 인코더 불러오기\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "total_tokens = 0\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"checking tokens\"):\n",
    "\tif pd.isna(row.url) or row.url == '':\n",
    "\t\tcontinue\n",
    "\n",
    "\tcode = str(row.code).zfill(6)\n",
    "\ttext_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "\tos.makedirs(text_dir, exist_ok=True)\n",
    "    \n",
    "\ttry:\n",
    "\t\tfilename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "\t\twith open(text_dir + filename, \"r\", encoding=\"utf-8\") as file:\n",
    "\t\t\ttext = file.read()\n",
    "\t\t\tsystem_prompt = \"\"\"\n",
    "\t\t너는 경제 전문 뉴스 분석 AI야. 사용자가 지정한 종목(회사명)과 직접적으로 관련된 정보만 선택해 핵심적으로 요약해.\n",
    "\t\t사실 기반으로 요약하고, 감성이나 추론이 필요한 경우에는 중립적으로 표현해.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t\tuser_prompt = f\"\"\"\n",
    "\t\t다음은 경제 뉴스 기사입니다.\n",
    "\n",
    "\t\t이 기사에서 **한국 상장 기업 \"{code}\"**과 관련된 내용만 골라 요약해 주세요.\n",
    "\n",
    "\t\t요약 기준:\n",
    "\t\t- \"{code}\"이 언급된 부분 중심\n",
    "\t\t- 관련 사업, 실적, 주가, 시장 반응, 경쟁사와의 연관성\n",
    "\t\t- 정부 정책, 산업 트렌드 등 외부 요인 중 관련 있는 부분\n",
    "\t\t- 부정적/긍정적 논조도 간단히 언급 (있는 경우)\n",
    "\n",
    "\t\t형식은 간결한 문장 또는 Bullet Point 형식으로 작성해 주세요.\n",
    "\n",
    "\t\t기사 전문:\n",
    "\t\t{text}\n",
    "\t\t\"\"\"\n",
    "\t\t\ttotal_prompt = system_prompt + user_prompt\n",
    "\t\t\ttokens = encoding.encode(total_prompt)\n",
    "\t\t\ttotal_tokens += len(tokens)\n",
    "\t\twith open('data_kr/video/num_token.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "\t\t\ttimestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "\t\t\tlog_file.write(f\"{text_dir}{filename} len: {len(text)}, token: {len(tokens)}\\n\")\n",
    "\texcept Exception as e:\n",
    "\t\twith open('data_kr/video/num_token.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "\t\t\ttimestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "\t\t\tlog_file.write(f\"{text_dir}{filename} error: \" + e + \"\\n\")\n",
    "\n",
    "with open('data_kr/video/num_token.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "\tlog_file.write(f\"total tokens: {total_tokens}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d9d4c-6adf-4f55-b874-ecfb5d6b58a7",
   "metadata": {},
   "source": [
    "### LLM으로 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e4c23-ba5a-4768-8ded-6e69e51f8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_stock_outlook import summarize_text\n",
    "\n",
    "df = pd.read_csv(\"data_kr/video/자료 수집 최종본.csv\")\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df), desc=\"LLM summarizing\"):\n",
    "    if pd.isna(row.url) or row.url == '':\n",
    "        continue\n",
    "\n",
    "    code = str(row.code).zfill(6)\n",
    "    name = row.name\n",
    "    text_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "    summary_dir = f'preprocessed_data/llm/summary/{row.sector}/{code}/'\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "        \n",
    "    try:\n",
    "        filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "        stock = f'{name}({code})'\n",
    "        with open(text_dir + filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        summary = summarize_text(text, stock)\n",
    "        with open(summary_dir + filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summary)\n",
    "        with open('preprocessed_data/llm/summary/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} summary completed: {summary_dir + filename}\\n\")\n",
    "    except Exception as e:\n",
    "        with open('preprocessed_data/llm/summary/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "            timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "            log_file.write(f\"{timestamp} summary error: {summary_dir + filename}\\t error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f08c86-f82f-476a-b5a9-a9c47e242a4d",
   "metadata": {},
   "source": [
    "### LLM으로 기사 자막요약을 통해 등락 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ea05f01-d708-4647-bce7-2cdbad1dcf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 8730.11it/s]\n",
      "150LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 14925.83it/s]\n",
      "660LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 13262.21it/s]\n",
      "1120LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 9562.77it/s]\n",
      "3490LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 9506.46it/s]\n",
      "3550LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 14237.38it/s]\n",
      "3570LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 15744.56it/s]\n",
      "4710LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 20865.66it/s]\n",
      "5930LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 13559.17it/s]\n",
      "6260LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 13057.59it/s]\n",
      "6400LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 8530.11it/s]\n",
      "8060LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 9788.23it/s]\n",
      "9150LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 8942.71it/s]\n",
      "10120LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 8564.00it/s]\n",
      "11070LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 9029.34it/s]\n",
      "11200LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 9130.51it/s]\n",
      "18260LLM predicting: 100%|██████████████████████████████████████████████████| 204/204 [00:00<00:00, 11747.30it/s]\n",
      "20150LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 8473.17it/s]\n",
      "25540LLM predicting: 100%|██████████████████████████████████████████████████| 204/204 [00:00<00:00, 19189.01it/s]\n",
      "29530LLM predicting: 100%|██████████████████████████████████████████████████| 204/204 [00:00<00:00, 26867.99it/s]\n",
      "34220LLM predicting: 100%|██████████████████████████████████████████████████| 204/204 [00:00<00:00, 10083.17it/s]\n",
      "34730LLM predicting: 100%|██████████████████████████████████████████████████| 204/204 [00:00<00:00, 10090.90it/s]\n",
      "42700LLM predicting: 100%|██████████████████████████████████████████████████| 204/204 [00:00<00:00, 11318.56it/s]\n",
      "47050LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 8009.94it/s]\n",
      "47810LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 9743.09it/s]\n",
      "51600LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 9409.03it/s]\n",
      "66570LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 8764.18it/s]\n",
      "86280LLM predicting: 100%|██████████████████████████████████████████████████| 204/204 [00:00<00:00, 11823.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from predict_stock_outlook import predict_market_from_summary\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_kr/video/뉴스 기사 수집본.csv', encoding='utf-8')\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    \n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\n",
    "        name = row.name\n",
    "        article_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "        predict_dir = f'preprocessed_data/llm/predict_text/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{article_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                article = file.read()\n",
    "            data = predict_market_from_summary(article, f'{name}({code})')\n",
    "            \n",
    "            with open(f'{predict_dir}{filename}', \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(data)\n",
    "            \n",
    "            with open('preprocessed_data/llm/predict_text/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict completed: {predict_dir}{filename}\\n\")\n",
    "        except Exception as e:\n",
    "            with open('preprocessed_data/llm/predict_text/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict error: {predict_dir}{filename}\\n\")\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf24048-7d41-471e-855b-d400cca54424",
   "metadata": {},
   "source": [
    "### LLM으로 영상 자막요약을 통해 등락 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b5f5a3-0b98-4438-8975-64355fd06d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120LLM predicting: 100%|███████████████████████████████████████████████████████| 204/204 [04:28<00:00,  1.32s/it]\n",
      "150LLM predicting: 100%|███████████████████████████████████████████████████████| 204/204 [05:04<00:00,  1.49s/it]\n",
      "660LLM predicting: 100%|███████████████████████████████████████████████████████| 204/204 [05:44<00:00,  1.69s/it]\n",
      "1120LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [03:06<00:00,  1.09it/s]\n",
      "3490LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [04:49<00:00,  1.42s/it]\n",
      "3550LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [05:58<00:00,  1.76s/it]\n",
      "3570LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [01:28<00:00,  2.31it/s]\n",
      "4710LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:44<00:00,  4.55it/s]\n",
      "5930LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [05:34<00:00,  1.64s/it]\n",
      "6260LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [02:42<00:00,  1.26it/s]\n",
      "6400LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [04:42<00:00,  1.38s/it]\n",
      "8060LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [04:44<00:00,  1.40s/it]\n",
      "9150LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [04:01<00:00,  1.19s/it]\n",
      "10120LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [04:22<00:00,  1.29s/it]\n",
      "11070LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [03:27<00:00,  1.02s/it]\n",
      "11200LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [03:16<00:00,  1.04it/s]\n",
      "18260LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [03:54<00:00,  1.15s/it]\n",
      "20150LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [03:45<00:00,  1.10s/it]\n",
      "25540LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:35<00:00,  5.68it/s]\n",
      "29530LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:08<00:00, 23.89it/s]\n",
      "34220LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [04:13<00:00,  1.24s/it]\n",
      "34730LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [04:04<00:00,  1.20s/it]\n",
      "42700LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [03:18<00:00,  1.03it/s]\n",
      "47050LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [03:49<00:00,  1.12s/it]\n",
      "47810LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [04:27<00:00,  1.31s/it]\n",
      "51600LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [03:23<00:00,  1.00it/s]\n",
      "66570LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [04:55<00:00,  1.45s/it]\n",
      "86280LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [02:20<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from predict_stock_outlook import predict_market_from_summary\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\t\n",
    "        name = row.name\n",
    "        script_dir = f'data_kr/video/script/{row.sector}/{code}/'\n",
    "        predict_dir = f'preprocessed_data/llm/predict_video/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{script_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                script = file.read()\n",
    "            prediction = predict_market_from_summary(script, f'{name}({code})')\n",
    "            \n",
    "            with open(f'{predict_dir}{filename}', \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(prediction)\n",
    "            \n",
    "            with open('preprocessed_data/llm/predict_video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict completed: {predict_dir}{filename}\\n\")\n",
    "        except Exception as e:\n",
    "            with open('preprocessed_data/llm/predict_video/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict error: {predict_dir}{filename}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684e553-90a5-401e-bbd4-ff1bde25fb2b",
   "metadata": {},
   "source": [
    "### LLM으로 영상자막요약 + 기사자막요약을 통해 등락 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e394fd-4a0c-4b3e-9976-76fcd09e4996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120LLM predicting:  80%|████████████████████████████████████████████▏          | 164/204 [04:10<01:06,  1.65s/it]"
     ]
    }
   ],
   "source": [
    "from predict_stock_outlook import predict_market_from_mix\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "df_v = pd.read_csv('data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')\n",
    "df_v.rename(columns={'url':'v_url', 'upload_dt':'v_upload_dt'}, inplace=True)\n",
    "df_v = df_v[[\"year\",\"quarter\",\"month\",\"week\",\"code\",\"name\",\"sector\",\"after\",\"before\",\"v_url\",\"v_upload_dt\"]]\n",
    "\n",
    "df_a = pd.read_csv('data_kr/video/뉴스 기사 수집본.csv', encoding='utf-8')\n",
    "df_a.rename(columns={'url':'a_url', 'upload_dt':'a_upload_dt'}, inplace=True)\n",
    "df_a = df_a[[\"a_url\",\"a_upload_dt\"]]\n",
    "\n",
    "df = pd.concat([df_v, df_a], axis=1)\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.v_url) or pd.isna(row.a_url) :\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\n",
    "        name = row.name\n",
    "        v_summary_dir = f'data_kr/video/script/{row.sector}/{code}/'\n",
    "        t_summary_dir = f'data_kr/video/text/{row.sector}/{code}/'\n",
    "        predict_dir = f'preprocessed_data/llm/predict_mix/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            stock = f'{name}({code})'\n",
    "            with open(f'{v_summary_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                script = file.read()\n",
    "            with open(f'{t_summary_dir}{filename}', \"r\", encoding=\"utf-8\") as file:\n",
    "                article = file.read()\n",
    " \n",
    "            data = predict_market_from_mix(article, script, f'{name}({code})')\n",
    "            \n",
    "            with open(f'{predict_dir}{filename}', \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(data)\n",
    "            \n",
    "            with open('preprocessed_data/llm/predict_mix/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict completed: {predict_dir}{filename}\\n\")\n",
    "        except Exception as e:\n",
    "            with open('preprocessed_data/llm/predict_mix/log.txt', \"a\", encoding=\"utf-8\") as log_file:\n",
    "                timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "                log_file.write(f\"{timestamp} predict error: {predict_dir}{filename}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a9a1b-c4ca-473d-917e-86af4d5e011c",
   "metadata": {},
   "source": [
    "### 기사 예측 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c5e488-346e-4161-8b26-ee4ab9d49bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 309.13it/s]\n",
      "150LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 503.33it/s]\n",
      "660LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 495.80it/s]\n",
      "1120LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 344.22it/s]\n",
      "3490LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 356.78it/s]\n",
      "3550LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 473.17it/s]\n",
      "3570LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 678.66it/s]\n",
      "4710LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 659.99it/s]\n",
      "5930LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 524.24it/s]\n",
      "6260LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 444.55it/s]\n",
      "6400LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 367.04it/s]\n",
      "8060LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 378.75it/s]\n",
      "9150LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 381.81it/s]\n",
      "10120LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 414.21it/s]\n",
      "11070LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 354.56it/s]\n",
      "11200LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 344.78it/s]\n",
      "18260LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 457.07it/s]\n",
      "20150LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 335.53it/s]\n",
      "25540LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 719.82it/s]\n",
      "29530LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 728.42it/s]\n",
      "34220LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 336.66it/s]\n",
      "34730LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 366.46it/s]\n",
      "42700LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 393.26it/s]\n",
      "47050LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 330.26it/s]\n",
      "47810LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 379.98it/s]\n",
      "51600LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 343.03it/s]\n",
      "66570LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 280.86it/s]\n",
      "86280LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 367.16it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('./data_kr/video/뉴스 기사 수집본.csv', encoding='utf-8')\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            score_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\t\n",
    "        name = row.name\n",
    "        predict_dir = f'preprocessed_data/llm/predict_text/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    " \n",
    "            with open(f'{predict_dir}{filename}', 'r', encoding='utf-8') as f:\n",
    "                # json.load() 함수를 사용하여 파일의 내용을 파이썬 딕셔너리로 불러옵니다.\n",
    "                data_dict = json.load(f)\n",
    "\n",
    "            predict_list.append(data_dict[\"sentiment\"])\n",
    "            reason_list.append(data_dict[\"reasoning\"])\n",
    "            score_list.append(data_dict[\"score\"])\n",
    "            \n",
    "        except Exception as e:\n",
    "            predict_list.append(\"중립\")\n",
    "            reason_list.append(\"관련 없음\")\n",
    "            score_list.append(0)\n",
    "            \n",
    "    df_predict = df_.copy()\n",
    "    df_predict[\"prediction\"] = predict_list\n",
    "    df_predict[\"reason\"] = reason_list\n",
    "    df_predict[\"score\"] = score_list\n",
    "    df_predict = df_predict[[\"year\", \"quarter\", \"month\", \"week\", \"code\", \"name\", \"sector\", \"upload_dt\", \"prediction\", \"reason\", \"score\"]]\n",
    "    df_predict.to_csv(f\"{predict_dir}{code}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95054901-f78d-4671-87aa-9e6931a13628",
   "metadata": {},
   "source": [
    "### 영상 예측 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0b1cdce-09e6-4828-8434-465f7dff3442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 311.70it/s]\n",
      "150LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 245.88it/s]\n",
      "660LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 262.12it/s]\n",
      "1120LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 479.64it/s]\n",
      "3490LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 313.68it/s]\n",
      "3550LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 333.18it/s]\n",
      "3570LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 1452.61it/s]\n",
      "4710LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 2275.42it/s]\n",
      "5930LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 289.48it/s]\n",
      "6260LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 474.92it/s]\n",
      "6400LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 338.23it/s]\n",
      "8060LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 327.93it/s]\n",
      "9150LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 368.60it/s]\n",
      "10120LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 344.49it/s]\n",
      "11070LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 396.72it/s]\n",
      "11200LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 402.38it/s]\n",
      "18260LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 320.98it/s]\n",
      "20150LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 407.29it/s]\n",
      "25540LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 2037.41it/s]\n",
      "29530LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 7324.23it/s]\n",
      "34220LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 289.93it/s]\n",
      "34730LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 301.14it/s]\n",
      "42700LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 383.29it/s]\n",
      "47050LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 352.94it/s]\n",
      "47810LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 285.32it/s]\n",
      "51600LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 400.60it/s]\n",
      "66570LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 295.72it/s]\n",
      "86280LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 491.22it/s]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('./data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.url) or row.url == '':\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            score_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\t\n",
    "        name = row.name\n",
    "        predict_dir = f'preprocessed_data/llm/predict_video/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "\n",
    "            with open(f'{predict_dir}{filename}', 'r', encoding='utf-8') as f:\n",
    "                # json.load() 함수를 사용하여 파일의 내용을 파이썬 딕셔너리로 불러옵니다.\n",
    "                data_dict = json.load(f)\n",
    "\n",
    "            predict_list.append(data_dict[\"sentiment\"])\n",
    "            reason_list.append(data_dict[\"reasoning\"])\n",
    "            score_list.append(data_dict[\"score\"])\n",
    "            \n",
    "        except Exception as e:\n",
    "            predict_list.append(\"불가능\")\n",
    "            reason_list.append(\"관련 없음\")\n",
    "            score_list.append(0)\n",
    "            \n",
    "    df_predict = df_.copy()\n",
    "    df_predict[\"prediction\"] = predict_list\n",
    "    df_predict[\"reason\"] = reason_list\n",
    "    df_predict[\"score\"] = score_list\n",
    "    df_predict = df_predict[[\"year\", \"quarter\", \"month\", \"week\", \"code\", \"name\", \"sector\", \"upload_dt\", \"prediction\", \"reason\", \"score\"]]\n",
    "    df_predict.to_csv(f\"{predict_dir}{code}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be3001-6d4b-4a19-850f-604b6a9662a6",
   "metadata": {},
   "source": [
    "### 영상+기사 예측 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79d33f16-ee3b-4595-b61d-de7db9e728c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 361.77it/s]\n",
      "150LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 435.05it/s]\n",
      "660LLM predicting: 100%|██████████████████████████████████████████████████████| 204/204 [00:00<00:00, 457.03it/s]\n",
      "1120LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 484.31it/s]\n",
      "3490LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 375.26it/s]\n",
      "3550LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 524.86it/s]\n",
      "3570LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 2038.85it/s]\n",
      "4710LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 2765.24it/s]\n",
      "5930LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 418.88it/s]\n",
      "6260LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 676.75it/s]\n",
      "6400LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 350.96it/s]\n",
      "8060LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 337.05it/s]\n",
      "9150LLM predicting: 100%|█████████████████████████████████████████████████████| 204/204 [00:00<00:00, 326.89it/s]\n",
      "10120LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 389.64it/s]\n",
      "11070LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 427.35it/s]\n",
      "11200LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 455.95it/s]\n",
      "18260LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:01<00:00, 198.04it/s]\n",
      "20150LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 443.21it/s]\n",
      "25540LLM predicting: 100%|███████████████████████████████████████████████████| 204/204 [00:00<00:00, 3009.09it/s]\n",
      "29530LLM predicting: 100%|██████████████████████████████████████████████████| 204/204 [00:00<00:00, 15911.74it/s]\n",
      "34220LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 411.28it/s]\n",
      "34730LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 403.67it/s]\n",
      "42700LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 379.09it/s]\n",
      "47050LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 388.32it/s]\n",
      "47810LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 444.70it/s]\n",
      "51600LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 506.36it/s]\n",
      "66570LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 358.37it/s]\n",
      "86280LLM predicting: 100%|████████████████████████████████████████████████████| 204/204 [00:00<00:00, 614.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from predict_stock_outlook import predict_market_from_mix\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_v = pd.read_csv('data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')\n",
    "df_v.rename(columns={'url':'v_url', 'upload_dt':'v_upload_dt'}, inplace=True)\n",
    "df_v = df_v[[\"year\",\"quarter\",\"month\",\"week\",\"code\",\"name\",\"sector\",\"after\",\"before\",\"v_url\",\"v_upload_dt\"]]\n",
    "\n",
    "df_a = pd.read_csv('data_kr/video/뉴스 기사 수집본.csv', encoding='utf-8')\n",
    "df_a.rename(columns={'url':'a_url', 'upload_dt':'a_upload_dt'}, inplace=True)\n",
    "df_a = df_a[[\"a_url\",\"a_upload_dt\"]]\n",
    "\n",
    "df = pd.concat([df_v, df_a], axis=1)\n",
    "\n",
    "for code in df[\"code\"].unique():\n",
    "    df_ = df[df[\"code\"] == code].reset_index(drop=True)\n",
    "    predict_list = []\n",
    "    reason_list = []\n",
    "    score_list = []\n",
    "    uploaddt_list = []\n",
    "\n",
    "    for row in tqdm(df_.itertuples(), total=len(df_), desc=f\"{code}LLM predicting\"):\n",
    "        if pd.isna(row.v_url) or pd.isna(row.a_url) :\n",
    "            predict_list.append(None)\n",
    "            reason_list.append(None)\n",
    "            score_list.append(None)\n",
    "            uploaddt_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        code = str(row.code).zfill(6)\n",
    "        name = row.name\n",
    "        predict_dir = f'preprocessed_data/llm/predict_mix/{row.sector}/{code}/'\n",
    "        os.makedirs(predict_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            filename = f'{row.year}-{row.quarter}-{str(row.month).zfill(2)}-{row.week}.txt'\n",
    "            \n",
    "            with open(f'{predict_dir}{filename}', 'r', encoding='utf-8') as f:\n",
    "                # json.load() 함수를 사용하여 파일의 내용을 파이썬 딕셔너리로 불러옵니다.\n",
    "                data_dict = json.load(f)\n",
    "\n",
    "            predict_list.append(data_dict[\"sentiment\"])\n",
    "            reason_list.append(data_dict[\"reasoning\"])\n",
    "            score_list.append(data_dict[\"score\"])\n",
    "            if not pd.isna(row.v_upload_dt) and not pd.isna(row.a_upload_dt):\n",
    "                uploaddt = row.v_upload_dt if row.v_upload_dt > row.a_upload_dt else row.a_upload_dt\n",
    "                uploaddt_list.append(uploaddt)\n",
    "            else:\n",
    "                uploaddt_list.append(None)\n",
    "                \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'error: {e}, file:{filename}')\n",
    "            predict_list.append(\"불가능\")\n",
    "            reason_list.append(\"관련 없음\")\n",
    "            score_list.append(0)\n",
    "            \n",
    "            \n",
    "    df_predict = df_.copy()\n",
    "    df_predict[\"prediction\"] = predict_list\n",
    "    df_predict[\"reason\"] = reason_list\n",
    "    df_predict[\"score\"] = score_list\n",
    "    df_predict['upload_dt'] = uploaddt_list\n",
    "    df_predict = df_predict[[\"year\", \"quarter\", \"month\", \"week\", \"code\", \"name\", \"sector\", \"upload_dt\", \"prediction\", \"reason\", \"score\"]]\n",
    "    df_predict.to_csv(f\"{predict_dir}{code}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08186f40-9496-4e66-9322-c5098757571d",
   "metadata": {},
   "source": [
    "## 예측 결과 정리 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8db379c-233c-48ec-a740-d938881d3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# 현재 폴더를 Path 객체로 만듭니다.\n",
    "# datas=['video', 'text', 'mix']\n",
    "datas=['text']\n",
    "for data in datas:\n",
    "    path_list = []\n",
    "    for sector in [\"산업재\", \"정보기술\"]:\n",
    "        root_path = Path(f'./preprocessed_data/llm/predict_{data}/{sector}')\n",
    "        \n",
    "        # rglob('*')는 재귀적으로 모든(*) 파일과 폴더를 찾습니다.\n",
    "        for path in root_path.rglob('*.csv'):\n",
    "            # path는 파일 또는 폴더에 대한 Path 객체입니다.\n",
    "            path_list.append(path)\n",
    "    df_list = [pd.read_csv(f'{path}', encoding='utf-8') for path in path_list]\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df = df.sort_values(by=['code', 'year', 'quarter', 'month', 'week'], ascending=True)\n",
    "    df.to_csv(f'./preprocessed_data/llm/predict_{data}/predict.csv', index=False, encoding='utf-8')\n",
    "    df.to_csv(f'./preprocessed_data/llm/predict_total/predict_{data}.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf8014-2226-421d-b3e7-552eb0776904",
   "metadata": {},
   "source": [
    "## mix에 video or text 단독예측도 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54019e35-233a-4065-898d-8f5244976108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_v = pd.read_csv('preprocessed_data/llm/predict_total/predict_video.csv', encoding='utf-8')\n",
    "df_t = pd.read_csv('preprocessed_data/llm/predict_total/predict_text.csv', encoding='utf-8')\n",
    "df_m = pd.read_csv('preprocessed_data/llm/predict_total/predict_mix.csv', encoding='utf-8')\n",
    "\n",
    "df_total = df_m.copy()\n",
    "df_total[pd.isna(df_total)] = df_v[pd.isna(df_total)]\n",
    "df_total[pd.isna(df_total)] = df_t[pd.isna(df_total)]\n",
    "\n",
    "df_total.to_csv('preprocessed_data/llm/predict_total/predict_total.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07fb5d-bd32-4a5e-bc31-4a1fc0de3100",
   "metadata": {},
   "source": [
    "## LLM 정확도 측정 (업로드일과 일주일 마감일 가격 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a9ceff-bdc7-4ffb-9cfb-7ee6f19325f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 5712/5712 [00:25<00:00, 222.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 5712/5712 [00:25<00:00, 220.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 5712/5712 [00:24<00:00, 230.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 5712/5712 [00:25<00:00, 225.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def get_pred_accuracy():\n",
    "    plt.figure(figsize=(24, 5))\n",
    "    \n",
    "    datas = ['video', 'text', 'mix', 'total']\n",
    "    \n",
    "    for idx, data in enumerate(datas):\n",
    "        df = pd.read_csv(f'preprocessed_data/llm/predict_total/predict_{data}.csv', encoding='utf-8')\n",
    "        df_d = pd.read_csv(f'data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')[['after', 'before']]\n",
    "        df = pd.concat([df, df_d], axis=1)\n",
    "        df[['upload_dt', 'after', 'before']] = df[['upload_dt', 'after', 'before']].apply(pd.to_datetime)\n",
    "        \n",
    "        ### LLM 예측에 실제 등락 라벨 추가 ###\n",
    "        df[\"code\"] = df[\"code\"].astype(str).str.zfill(6)\n",
    "        \n",
    "        price_upload = [] # 업로드 당일 종가\n",
    "        price_end = [] # 공시 당일 종가\n",
    "        for row in tqdm(df.itertuples(), total=len(df)):\n",
    "            df_price = pd.read_csv(f\"data_kr/price/{row.code}.csv\")\n",
    "            df_price['날짜'] = pd.to_datetime(df_price['날짜'])\n",
    "            ### 업로드 날짜 직전 종가\n",
    "            price_upload.append(df_price.loc[df_price[\"날짜\"] < row.upload_dt, \"종가\"].iloc[-1] if not pd.isna(row.upload_dt) else None)\n",
    "            ### 데이터 업로드 주간 마지막 날 종가\n",
    "            price_end.append(df_price.loc[df_price[\"날짜\"] < row.before, \"종가\"].iloc[-1] if not pd.isna(row.before) else None)\n",
    "        \n",
    "        df[\"price_upload\"] = price_upload\n",
    "        df[\"price_end\"] = price_end\n",
    "    \n",
    "        def check_change(row):\n",
    "            rate = (row[\"price_end\"] / row[\"price_upload\"] - 1) * 100\n",
    "            if rate > 0:\n",
    "                return \"상승\"\n",
    "            else:\n",
    "                return \"하락\"\n",
    "        df[\"label\"] = df.apply(check_change, axis=1)\n",
    "\n",
    "        ###############################################################\n",
    "        ### 유효한 데이터만 남기기 ###\n",
    "        valid_bool = ~(pd.isna(df['prediction']) | (df['prediction'] == '중립'))\n",
    "        prediction = df[valid_bool]['prediction']\n",
    "        label = df[valid_bool]['label']\n",
    "        \n",
    "        mapping = {'매우 긍정': '상승', '긍정': '상승', '중립': '횡보', '부정': '하락', '매우 부정': '하락'}\n",
    "        prediction = [mapping[l] for l in prediction]\n",
    "        \n",
    "        # 혼동 행렬\n",
    "        labels = [\"상승\", \"하락\"]\n",
    "        cm = confusion_matrix(label, prediction, labels=labels)\n",
    "        \n",
    "        # 한글 폰트 설정 (Windows, Mac, Linux 환경에 맞게 설정)\n",
    "        # 윈도우\n",
    "        plt.rc('font', family='Malgun Gothic')\n",
    "    \n",
    "        # 시각화\n",
    "        plt.subplot(1, 4, idx + 1)  # 1행 3열 중 i번째 위치에 subplot을 생성\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Label')\n",
    "        plt.title(f'{data} Accuracy Confusion Matrix')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"preprocessed_data/llm/predict_total/predict_accuracy.png\")\n",
    "    plt.close()\n",
    "\n",
    "get_pred_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e8058-b0f2-402f-bcce-96bab5d24e97",
   "metadata": {},
   "source": [
    "## LLM 예측 정확도 지표 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "116f7d77-4450-4152-ad53-9cdd5ffe3e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 5712/5712 [00:25<00:00, 223.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 5712/5712 [00:25<00:00, 224.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 5712/5712 [00:24<00:00, 230.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 5712/5712 [00:25<00:00, 226.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video\n",
      "accuracy: 0.5234042553191489\n",
      "precision: 0.35118110236220473\n",
      "recall: 0.27228327228327226\n",
      "f1: 0.30674002751031637\n",
      "\n",
      "text\n",
      "accuracy: 0.5146666666666667\n",
      "precision: 0.33724340175953077\n",
      "recall: 0.11722731906218145\n",
      "f1: 0.17397881996974282\n",
      "\n",
      "mix\n",
      "accuracy: 0.5721223895094706\n",
      "precision: 0.3137254901960784\n",
      "recall: 0.2028169014084507\n",
      "f1: 0.24636441402908468\n",
      "\n",
      "total\n",
      "accuracy: 0.5596971461852067\n",
      "precision: 0.3209718670076726\n",
      "recall: 0.20373376623376624\n",
      "f1: 0.24925521350546176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def get_pred_accuracy():\n",
    "    scores = dict()\n",
    "    \n",
    "    datas = ['video', 'text', 'mix', 'total']\n",
    "    \n",
    "    for idx, data in enumerate(datas):\n",
    "        df = pd.read_csv(f'preprocessed_data/llm/predict_total/predict_{data}.csv', encoding='utf-8')\n",
    "        df_d = pd.read_csv(f'data_kr/video/뉴스 영상 수집본.csv', encoding='utf-8')[['after', 'before']]\n",
    "        df = pd.concat([df, df_d], axis=1)\n",
    "        df[['upload_dt', 'after', 'before']] = df[['upload_dt', 'after', 'before']].apply(pd.to_datetime)\n",
    "        \n",
    "        ### LLM 예측에 실제 등락 라벨 추가 ###\n",
    "        df[\"code\"] = df[\"code\"].astype(str).str.zfill(6)\n",
    "        \n",
    "        price_upload = [] # 업로드 당일 종가\n",
    "        price_end = [] # 공시 당일 종가\n",
    "        for row in tqdm(df.itertuples(), total=len(df)):\n",
    "            df_price = pd.read_csv(f\"data_kr/price/{row.code}.csv\")\n",
    "            df_price['날짜'] = pd.to_datetime(df_price['날짜'])\n",
    "            ### 업로드 날짜 직전 종가\n",
    "            price_upload.append(df_price.loc[df_price[\"날짜\"] < row.upload_dt, \"종가\"].iloc[-1] if not pd.isna(row.upload_dt) else None)\n",
    "            ### 데이터 업로드 주간 마지막 날 종가\n",
    "            price_end.append(df_price.loc[df_price[\"날짜\"] < row.before, \"종가\"].iloc[-1] if not pd.isna(row.before) else None)\n",
    "        \n",
    "        df[\"price_upload\"] = price_upload\n",
    "        df[\"price_end\"] = price_end\n",
    "    \n",
    "        def check_change(row):\n",
    "            rate = (row[\"price_end\"] / row[\"price_upload\"] - 1) * 100\n",
    "            if rate > 0:\n",
    "                return \"상승\"\n",
    "            else:\n",
    "                return \"하락\"\n",
    "        df[\"label\"] = df.apply(check_change, axis=1)\n",
    "\n",
    "        ###############################################################\n",
    "        ### 유효한 데이터만 남기기 ###\n",
    "        valid_bool = ~(pd.isna(df['prediction']) | (df['prediction'] == '중립'))\n",
    "        prediction = df[valid_bool]['prediction']\n",
    "        label = df[valid_bool]['label']\n",
    "        \n",
    "        mapping = {'매우 긍정': '상승', '긍정': '상승', '중립': '횡보', '부정': '하락', '매우 부정': '하락'}\n",
    "        prediction = [mapping[l] for l in prediction]\n",
    "        \n",
    "\n",
    "        accuracy = accuracy_score(label, prediction)\n",
    "        precision = precision_score(label, prediction, pos_label='상승', zero_division=0)\n",
    "        recall = recall_score(label, prediction, pos_label='상승', zero_division=0)\n",
    "        f1 = f1_score(label, prediction, pos_label='상승', zero_division=0)\n",
    "\n",
    "        score_dict = {'accuracy': accuracy, 'precision':precision, 'recall':recall, 'f1':f1}\n",
    "        scores[data] = score_dict\n",
    "\n",
    "    for data in datas:\n",
    "        print(f'{data}\\naccuracy: {scores[data]['accuracy']}\\nprecision: {scores[data]['precision']}\\nrecall: {scores[data]['recall']}\\nf1: {scores[data]['f1']}\\n')\n",
    "get_pred_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbfe49-8fc9-4fd5-b766-5c39bff46c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3ce_kernel",
   "language": "python",
   "name": "s3ce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
